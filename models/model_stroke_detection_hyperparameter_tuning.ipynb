{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "!pip install hyperas\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import Session\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    ##Import data from hd5f file\n",
    "    PATH_3D_H5 = 'Images/preprocessed_data_128_112_40.hdf5'\n",
    "    with h5py.File(PATH_3D_H5, 'r') as h5:\n",
    "        print('H5-file: ', list(h5.keys()))\n",
    "\n",
    "         # Training data\n",
    "        X_train = h5[\"X_train\"][:]\n",
    "        Y_train = h5[\"Y_train\"][:]\n",
    "        pat_train = h5[\"pat_train\"][:]\n",
    "        \n",
    "        # Validation data\n",
    "        X_valid = h5[\"X_valid\"][:]\n",
    "        Y_valid = h5[\"Y_valid\"][:]\n",
    "        pat_valid = h5[\"pat_valid\"][:]\n",
    "\n",
    "        # Test\n",
    "        X_test = h5[\"X_test\"][:]\n",
    "        Y_test = h5[\"Y_test\"][:]\n",
    "        pat_test = h5[\"pat_test\"][:]\n",
    "\n",
    "    print(X_train.shape, X_train.min(), X_train.max(), X_train.mean(), X_train.std(), Y_train.shape)\n",
    "    print(X_valid.shape, X_valid.min(), X_valid.max(), X_valid.mean(), X_valid.std(), Y_valid.shape)\n",
    "    print(X_test.shape, X_test.min(), X_test.max(), X_test.mean(), X_test.std(), Y_test.shape)\n",
    "    \n",
    "    ###Create balanced dataset\n",
    "    bool_train_labels = Y_train[:,1] != 0\n",
    "    pos_features = X_train[bool_train_labels]\n",
    "    neg_features = X_train[~bool_train_labels]\n",
    "    pos_labels = Y_train[bool_train_labels]\n",
    "    neg_labels = Y_train[~bool_train_labels]\n",
    "\n",
    "    ids = np.arange(len(neg_features))\n",
    "    choices = np.random.choice(ids, len(pos_features))\n",
    "    res_neg_features = neg_features[choices]\n",
    "    res_neg_labels = neg_labels[choices]\n",
    "\n",
    "    resampled_features = np.concatenate([res_neg_features, pos_features], axis=0)\n",
    "    resampled_labels = np.concatenate([res_neg_labels, pos_labels], axis=0)\n",
    "\n",
    "    order = np.arange(len(resampled_labels))\n",
    "    np.random.shuffle(order)\n",
    "    X_train_balanced = resampled_features[order]\n",
    "    Y_train_balanced = resampled_labels[order]\n",
    "\n",
    "    print(X_train_balanced.shape, Y_train_balanced.shape)\n",
    "    \n",
    "    return X_train_balanced, Y_train_balanced, X_valid, Y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_valid, Y_valid):  \n",
    "    num_classes = 2\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Convolution3D({{choice([8, 16, 32])}}, kernel_size=3, activation=\"relu\", \n",
    "                                   batch_input_shape=(None,128,112,40,1), padding = 'same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size = 2))\n",
    "    model.add(layers.BatchNormalization(center = True, scale = True))\n",
    "    \n",
    "    model.add(layers.Convolution3D({{choice([8, 16, 32])}}, kernel_size=3, activation=\"relu\", padding = 'same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size = 2))\n",
    "    model.add(layers.BatchNormalization(center = True, scale = True))\n",
    "    \n",
    "    model.add(layers.Convolution3D({{choice([16, 32, 64])}}, kernel_size=3, activation=\"relu\", padding = 'same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size = 2))\n",
    "    model.add(layers.BatchNormalization(center = True, scale = True))\n",
    "    \n",
    "    model.add(layers.Convolution3D({{choice([16, 32, 64])}}, kernel_size=3, activation=\"relu\", padding = 'same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size = 2))\n",
    "    model.add(layers.BatchNormalization(center = True, scale = True))\n",
    "    \n",
    "    model.add(layers.Convolution3D({{choice([32, 64, 128])}}, kernel_size=3, activation=\"relu\", padding = 'same'))\n",
    "    model.add(layers.MaxPooling3D(pool_size = 2, padding = 'same'))\n",
    "    model.add(layers.BatchNormalization(center = True, scale = True))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense({{choice([32, 64, 128])}}, activation=\"relu\"))\n",
    "    model.add(layers.Dropout({{uniform(0, 0.6)}}))\n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "              \n",
    "    #compile model\n",
    "    metrics = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.AUC(name='auc')]\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "                  metrics=metrics)\n",
    "    \n",
    "    history = model.fit(X_train_balanced, Y_train_balanced,\n",
    "                        validation_data=(X_valid, Y_valid), \n",
    "                        batch_size=2,\n",
    "                        verbose=2,\n",
    "                        epochs=50)\n",
    "    \n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    val_auc = np.amax(history.history['val_auc']) \n",
    "    print('Best validation auc of epoch:', val_auc)\n",
    "              \n",
    "    return {'loss': val_auc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      max_evals=25,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      notebook_name=\"Modell_Schlaganfall_Detektion_Hyperparameter_Optimierung\", # Without this it can't find the notebook!\n",
    "                                      trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from Functions.data_import import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-recommendation",
   "metadata": {},
   "source": [
    "### Import patient IDs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Schule/OneDrive/Studium ZHAW/Bachelorarbeit/Image import/patids_withlabel.xlsx\"\n",
    "patids_labels = pd.read_excel(path)\n",
    "patids_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-valuable",
   "metadata": {},
   "source": [
    "### Create path file for TOF-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"D:\\Pat_\"\n",
    "def get_paths_tof(pat_id):\n",
    "    DIR = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_TOF\"\n",
    "    folder = os.listdir(DIR)[0]\n",
    "    DIR = DIR+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR)[0]\n",
    "    DIR = DIR+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR)[0]\n",
    "    DIR = DIR+\"\\\\\"+folder\n",
    "        \n",
    "    return(DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_id = 1\n",
    "DIR = get_paths_tof(pat_id) #get directory for TOF images\n",
    "files = get_files_in_directory(DIR)\n",
    "batch_df = pd.DataFrame()\n",
    "for index, file in enumerate(files):\n",
    "        DICOM_file = pydicom.read_file(file)\n",
    "\n",
    "        batch_df.loc[index, 'patient'] = pat_id\n",
    "        batch_df.loc[index, 'filepath'] = file\n",
    "        batch_df.loc[index, 'sequence'] = DICOM_file.SequenceName \n",
    "        batch_df.loc[index, 'thickness'] = DICOM_file.SliceThickness\n",
    "        \n",
    "batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in pat_ids:\n",
    "    try: \n",
    "        batch_df = get_file_list(i)\n",
    "        df = df.append(batch_df)\n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "image_info_dir = 'C:/Users/Schule/OneDrive/Studium ZHAW/Bachelorarbeit/Image import/file_paths_tof.csv'\n",
    "if os.path.exists(image_info_dir):\n",
    "    os.remove(image_info_dir)\n",
    "with open(image_info_dir, 'a') as f:\n",
    "        df.to_csv(f, header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-wound",
   "metadata": {},
   "source": [
    "### Create path file for 3D-Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_ids_3d2 = (patids_labels[\"zwei_Bilder\"].dropna()).tolist()\n",
    "pat_ids_3d3 = (patids_labels[\"drei_Bilder\"].dropna()).tolist()\n",
    "pat_ids_3d0 = (patids_labels[\"kein_Bild\"].dropna()).tolist()\n",
    "pat_ids_3d1 = [i for i in patids_labels.ID if i not in pat_ids_3d2 and i not in pat_ids_3d3 and i not in pat_ids_3d0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_3d1(pat_id):\n",
    "    DIR = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_3D\"\n",
    "    folder = os.listdir(DIR)[0]\n",
    "    DIR = DIR+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR)[0]\n",
    "    DIR = DIR+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR)[0]\n",
    "    DIR = DIR+\"\\\\\"+folder\n",
    "    \n",
    "    return DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_3d2(pat_id):\n",
    "    DIR1 = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_3D1\"\n",
    "    folder = os.listdir(DIR1)[0]\n",
    "    DIR1 = DIR1+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR1)[0]\n",
    "    DIR1 = DIR1+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR1)[0]\n",
    "    DIR1 = DIR1+\"\\\\\"+folder\n",
    "\n",
    "    ##Folder 3D2\n",
    "    DIR2 = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_3D2\"\n",
    "    folder = os.listdir(DIR2)[0]\n",
    "    DIR2 = DIR2+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR2)[0]\n",
    "    DIR2 = DIR2+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR2)[0]\n",
    "    DIR2 = DIR2+\"\\\\\"+folder\n",
    "    \n",
    "    return (DIR1, DIR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths_3d3(pat_id):\n",
    "    DIR1 = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_3D1\"\n",
    "    folder = os.listdir(DIR1)[0]\n",
    "    DIR1 = DIR1+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR1)[0]\n",
    "    DIR1 = DIR1+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR1)[0]\n",
    "    DIR1 = DIR1+\"\\\\\"+folder\n",
    "\n",
    "    ##Folder 3D2\n",
    "    DIR2 = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_3D2\"\n",
    "    folder = os.listdir(DIR2)[0]\n",
    "    DIR2 = DIR2+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR2)[0]\n",
    "    DIR2 = DIR2+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR2)[0]\n",
    "    DIR2 = DIR2+\"\\\\\"+folder\n",
    "    \n",
    "    ##Folder 3D3\n",
    "    DIR3 = root_dir+str(pat_id)+\"\\Pat\"+str(pat_id)+\"_3D3\"\n",
    "    folder = os.listdir(DIR3)[0]\n",
    "    DIR3 = DIR3+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR3)[0]\n",
    "    DIR3 = DIR3+\"\\\\\"+folder\n",
    "    folder = os.listdir(DIR3)[0]\n",
    "    DIR3 = DIR3+\"\\\\\"+folder\n",
    "    \n",
    "    return (DIR1, DIR2, DIR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list_3d(pat_id):\n",
    "    if pat_id in pat_ids_3d1:\n",
    "        image_dir = get_paths_3d1(pat_id)\n",
    "        listFilesDICOM = get_files_in_directory(image_dir)\n",
    "        \n",
    "    if pat_id in pat_ids_3d2:\n",
    "        image_dir1, image_dir2 = get_paths_3d2(pat_id)\n",
    "        listFilesDICOM1 = get_files_in_directory(image_dir1)\n",
    "        listFilesDICOM2 = get_files_in_directory(image_dir2)\n",
    "        listFilesDICOM = listFilesDICOM1 + listFilesDICOM2\n",
    "        \n",
    "    if pat_id in pat_ids_3d3:\n",
    "        image_dir1, image_dir2, image_dir3 = get_paths_3d3(pat_id)\n",
    "        listFilesDICOM1 = get_files_in_directory(image_dir1)\n",
    "        listFilesDICOM2 = get_files_in_directory(image_dir2)\n",
    "        listFilesDICOM3 = get_files_in_directory(image_dir3)\n",
    "        listFilesDICOM = listFilesDICOM1 + listFilesDICOM2 + listFilesDICOM3\n",
    "        \n",
    "    batch_df = pd.DataFrame()\n",
    "    for index, file in enumerate(listFilesDICOM):\n",
    "        DICOM_file = pydicom.read_file(file)\n",
    "\n",
    "        try:\n",
    "            batch_df.loc[index, 'patient'] = pat_id\n",
    "            batch_df.loc[index, 'instancenumber'] = DICOM_file.InstanceNumber\n",
    "            batch_df.loc[index, 'seriesInstanceUID'] = DICOM_file.SeriesInstanceUID\n",
    "            batch_df.loc[index, 'filepath'] = file\n",
    "\n",
    "        except Exception as e:\n",
    "            print('file {} cannot be loaded.'.format(file))\n",
    "            print(e)\n",
    "            \n",
    "    return batch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in pat_ids:\n",
    "    try: \n",
    "        batch_df = get_file_list_3d(i)\n",
    "        df = df.append(batch_df)\n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "image_info_dir = 'D:\\\\file_paths_3D.csv'\n",
    "if os.path.exists(image_info_dir):\n",
    "    os.remove(image_info_dir)\n",
    "with open(image_info_dir, 'a') as f:\n",
    "        df.to_csv(f, header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-sleeping",
   "metadata": {},
   "source": [
    "### Import File with paths to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_IMAGE_INFO = 'C:/Users/Schule/OneDrive/Studium ZHAW/Bachelorarbeit/Image import/file_paths_tof.csv'\n",
    "data_info = pd.read_csv(PATH_IMAGE_INFO)\n",
    "names = ['pat_id','path', 'sequence', 'thickness']\n",
    "data_info.columns = names\n",
    "data_info['pat_id'] = data_info['pat_id'].astype(int)\n",
    "data_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-magnet",
   "metadata": {},
   "source": [
    "### Create HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMENSIONS_TOF = (128, 112, 40) #format for images \n",
    "first_patient = True\n",
    "\n",
    "if os.path.exists(PATH_3D_H5):\n",
    "    os.remove(PATH_3D_H5)\n",
    "    \n",
    "patient_list = list(set(data_info.pat_id))\n",
    "#patient_list = patient_list\n",
    "\n",
    "with h5py.File(PATH_3D_H5, 'a') as f:\n",
    "    for patient_number in patient_list:\n",
    "        patient_data = data_info[data_info.pat_id == patient_number].copy()\n",
    "        directory = get_paths_tof(patient_number)\n",
    "\n",
    "        #image to array\n",
    "        raw_3d_image = image_to_array(patient_number)\n",
    "\n",
    "        #resize image\n",
    "        scaled_3d_image = scale_array_3D(raw_3d_image, IMAGE_DIMENSIONS_TOF)\n",
    "\n",
    "        # Image matrices\n",
    "        X = scaled_3d_image[np.newaxis, :, :, :]\n",
    "\n",
    "        # Patient ID's\n",
    "        pat = format(patient_number, '03d')\n",
    "        pat = np.string_([pat])\n",
    "\n",
    "        #path to file with all images for patient\n",
    "        path = np.string_([directory]) \n",
    "\n",
    "        #labels 1 = stroke, 0 = TIA\n",
    "        Y_pat = patids_labels.label_short.loc[patids_labels.ID == patient_number].values\n",
    "        Y = np.array(Y_pat)\n",
    "\n",
    "        ## write to h5py sequentially\n",
    "        ms = [id for id in IMAGE_DIMENSIONS_TOF]\n",
    "        ms.insert(0, None)\n",
    "        ms = tuple(ms)\n",
    "\n",
    "        if first_patient: ## initialize dataset\n",
    "            f.create_dataset('X', data = X, maxshape = ms, chunks = True)\n",
    "            f.create_dataset('stroke', data = Y_pat, maxshape = (None,), chunks = True)\n",
    "            f.create_dataset('pat', data = pat, maxshape = (None,), chunks = True)\n",
    "            f.create_dataset('path', data = path, maxshape = (None,), chunks = True)\n",
    "            first_patient = False\n",
    "\n",
    "        else: ## append dataset\n",
    "            f['X'].resize((f['X'].shape[0] + X.shape[0]), axis = 0)\n",
    "            f['X'][-X.shape[0]:, :, :, :] = X\n",
    "            f['stroke'].resize((f['stroke'].shape[0] + Y_pat.shape[0]), axis = 0)\n",
    "            f['stroke'][-Y_pat.shape[0]:] = Y_pat\n",
    "            f['pat'].resize((f['pat'].shape[0] + pat.shape[0]), axis = 0)\n",
    "            f['pat'][-pat.shape[0]:] = pat\n",
    "            f['path'].resize((f['path'].shape[0] + path.shape[0]), axis = 0)\n",
    "            f['path'][-path.shape[0]:] = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-adoption",
   "metadata": {},
   "source": [
    "### Checking HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_3D_H5 = 'D:\\\\tof_data_128_112_40.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = h5py.File(PATH_3D_H5, 'r')\n",
    "list(dd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dd['X']\n",
    "np.max(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = [p.decode() for p in dd['pat']]\n",
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [p for p in dd['path']]\n",
    "path[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [p for p in dd['stroke']]\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

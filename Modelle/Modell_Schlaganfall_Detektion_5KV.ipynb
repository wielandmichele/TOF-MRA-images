{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "false-glory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.12.2-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.5 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting patsy>=0.5\n",
      "  Downloading patsy-0.5.1-py2.py3-none-any.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 31.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.5.4)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.19.4)\n",
      "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from statsmodels) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->statsmodels) (2021.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5->statsmodels) (1.15.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.1 statsmodels-0.12.2\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "front-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "import tempfile\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from functions.auc_delong_xu import auc_ci_Delong\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import Session\n",
    "import gc\n",
    "\n",
    "from Functions.data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ignored-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Functions.data_augmentation import *\n",
    "from Functions.data_import import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-telling",
   "metadata": {},
   "source": [
    "### Import data from HD5File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mobile-queen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H5-file:  ['X', 'Y_pat', 'pat']\n",
      "(508, 128, 112, 40, 1) -1.5907471988589987 26.031565772467758 2.1324024910545048e-18 0.9999999999999966 (508,) (508,)\n"
     ]
    }
   ],
   "source": [
    "PATH_3D_H5 = 'Images/preprocessed_data_128_112_40.hdf5'\n",
    "with h5py.File(PATH_3D_H5, 'r') as h5:\n",
    "    print('H5-file: ', list(h5.keys()))\n",
    "\n",
    "    X = h5[\"X\"][:]\n",
    "    Y_pat = h5[\"Y_pat\"][:]\n",
    "    pat = h5[\"pat\"][:]\n",
    "\n",
    "print(X.shape, X.min(), X.max(), X.mean(), X.std(), Y_pat.shape, pat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reverse-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def augment_3d_two(volume):\n",
    "    \"\"\"Randomly pick two data augmentation functions for every image\"\"\"\n",
    "\n",
    "    def augment(volume):\n",
    "        rand = np.random.randint(0,5, size = 2)\n",
    "            \n",
    "        if 0 in rand:\n",
    "            volume = random_zoom3d(volume, 0.8,1.3) \n",
    "        if 1 in rand:\n",
    "            volume = random_rotate3d(volume, -20, 20, -5, -5, -5, -5)\n",
    "        if 2 in rand:\n",
    "            volume = random_shift3d(volume, -20, 20, -20, 20, 0, 0) #do not shift in z direction\n",
    "        if 3 in rand:\n",
    "            volume = random_flip3d(volume)\n",
    "        if 4 in rand:\n",
    "            volume = random_gaussianfilter3d(volume, 0.2)\n",
    "            \n",
    "        return volume\n",
    "    \n",
    "    volume_shape = volume.shape\n",
    "    augmented_volume = tf.numpy_function(augment, [volume], np.float64)\n",
    "    augmented_volume = tf.reshape(augmented_volume, volume_shape)\n",
    "    return augmented_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "swedish-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_preprocessing(volume, label):\n",
    "    volume = augment_3d_two(volume)\n",
    "    return volume, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "closed-pizza",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(X_train, Y_train, X_valid, Y_valid):\n",
    "    Y_train = to_categorical(Y_train)\n",
    "    Y_valid = to_categorical(Y_valid)\n",
    "    \n",
    "    bool_train_labels = Y_train[:,1] != 0\n",
    "    pos_features = X_train[bool_train_labels]\n",
    "    neg_features = X_train[~bool_train_labels]\n",
    "    pos_labels = Y_train[bool_train_labels]\n",
    "    neg_labels = Y_train[~bool_train_labels]\n",
    "    \n",
    "    def make_ds(features, labels):\n",
    "        ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
    "        ds = ds.shuffle(len(pos_features)*2).repeat()\n",
    "        return ds\n",
    "\n",
    "    pos_ds = make_ds(pos_features, pos_labels)\n",
    "    neg_ds = make_ds(neg_features, neg_labels)\n",
    "    \n",
    "    resampled_ds = tf.data.experimental.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
    "    validation_loader = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid))\n",
    "\n",
    "    batch_size = 2\n",
    "    # Augment the on the fly during training.\n",
    "    train_dataset = (\n",
    "        resampled_ds.shuffle(buffer_size = (len(pos_features)*2), reshuffle_each_iteration=True)\n",
    "        .map(train_preprocessing)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(2))\n",
    "\n",
    "    validation_dataset = (\n",
    "        validation_loader.shuffle(len(X_valid))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(2))\n",
    "    \n",
    "    pos = len(pos_features)\n",
    "    neg = len(neg_features)\n",
    "    total = pos + neg\n",
    "    resampled_steps_per_epoch = np.ceil(2.0*pos/batch_size)\n",
    "    \n",
    "    weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "    weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "    class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "    print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "    print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "    \n",
    "    return train_dataset, validation_dataset, class_weight, batch_size, resampled_steps_per_epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "governmental-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(IMAGE_DIMENSION):\n",
    "    inputs = keras.Input(IMAGE_DIMENSION)\n",
    "\n",
    "    x = layers.Conv3D(filters=8, kernel_size=3, activation=\"relu\", padding = 'same')(inputs)\n",
    "    x = layers.AveragePooling3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Conv3D(filters=16, kernel_size=3, activation=\"relu\", padding = 'same')(x)\n",
    "    x = layers.AveragePooling3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\", padding = 'same')(x)\n",
    "    x = layers.AveragePooling3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\", padding = 'same')(x)\n",
    "    x = layers.AveragePooling3D(pool_size = 2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\", padding = 'same')(x)\n",
    "    x = layers.AveragePooling3D(pool_size = 2, padding = 'same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(units=64, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.Dropout(0.01)(x)\n",
    "\n",
    "    outputs = layers.Dense(units=2, activation=\"softmax\")(x)\n",
    "\n",
    "    # Define the model.\n",
    "    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-emphasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.61\n",
      "Weight for class 1: 0.73\n",
      "Model: \"3dcnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 112, 40, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv3d (Conv3D)              (None, 128, 112, 40, 32)  896       \n",
      "_________________________________________________________________\n",
      "average_pooling3d (AveragePo (None, 64, 56, 20, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 56, 20, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 64, 56, 20, 32)    27680     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_1 (Average (None, 32, 28, 10, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 28, 10, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 32, 28, 10, 32)    27680     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_2 (Average (None, 16, 14, 5, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 14, 5, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 16, 14, 5, 64)     55360     \n",
      "_________________________________________________________________\n",
      "average_pooling3d_3 (Average (None, 8, 7, 2, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 7, 2, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv3d_4 (Conv3D)            (None, 8, 7, 2, 64)       110656    \n",
      "_________________________________________________________________\n",
      "average_pooling3d_4 (Average (None, 4, 3, 1, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 3, 1, 64)       256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                49216     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 276,674\n",
      "Trainable params: 276,226\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n",
      "892\n",
      "Epoch 1/150\n",
      "105/105 [==============================] - 63s 514ms/step - loss: 1.0753 - accuracy: 0.6020 - auc: 0.5945 - categorical_crossentropy: 0.8568 - val_loss: 0.7461 - val_accuracy: 0.3069 - val_auc: 0.2859 - val_categorical_crossentropy: 0.7461\n",
      "\n",
      "Epoch 00001: saving model to History0/model.epoch01.hdf5\n",
      "Epoch 2/150\n",
      "105/105 [==============================] - 53s 509ms/step - loss: 0.9077 - accuracy: 0.5368 - auc: 0.5218 - categorical_crossentropy: 0.9833 - val_loss: 0.8430 - val_accuracy: 0.3069 - val_auc: 0.3120 - val_categorical_crossentropy: 0.8430\n",
      "\n",
      "Epoch 00002: saving model to History0/model.epoch02.hdf5\n",
      "Epoch 3/150\n",
      "105/105 [==============================] - 55s 521ms/step - loss: 0.9193 - accuracy: 0.5030 - auc: 0.4976 - categorical_crossentropy: 0.9056 - val_loss: 0.9642 - val_accuracy: 0.3069 - val_auc: 0.2761 - val_categorical_crossentropy: 0.9642\n",
      "\n",
      "Epoch 00003: saving model to History0/model.epoch03.hdf5\n",
      "Epoch 4/150\n",
      "105/105 [==============================] - 52s 490ms/step - loss: 0.8317 - accuracy: 0.5142 - auc: 0.5040 - categorical_crossentropy: 0.8478 - val_loss: 1.0230 - val_accuracy: 0.3168 - val_auc: 0.2969 - val_categorical_crossentropy: 1.0230\n",
      "\n",
      "Epoch 00004: saving model to History0/model.epoch04.hdf5\n",
      "Epoch 5/150\n",
      "105/105 [==============================] - 52s 487ms/step - loss: 0.9472 - accuracy: 0.4371 - auc: 0.4186 - categorical_crossentropy: 0.9539 - val_loss: 0.8146 - val_accuracy: 0.3465 - val_auc: 0.3371 - val_categorical_crossentropy: 0.8146\n",
      "\n",
      "Epoch 00005: saving model to History0/model.epoch05.hdf5\n",
      "Epoch 6/150\n",
      "105/105 [==============================] - 51s 489ms/step - loss: 0.8091 - accuracy: 0.4768 - auc: 0.4844 - categorical_crossentropy: 0.7903 - val_loss: 0.7722 - val_accuracy: 0.3663 - val_auc: 0.3161 - val_categorical_crossentropy: 0.7722\n",
      "\n",
      "Epoch 00006: saving model to History0/model.epoch06.hdf5\n",
      "Epoch 7/150\n",
      "105/105 [==============================] - 53s 503ms/step - loss: 0.8082 - accuracy: 0.5123 - auc: 0.5434 - categorical_crossentropy: 0.7759 - val_loss: 0.9063 - val_accuracy: 0.3267 - val_auc: 0.2744 - val_categorical_crossentropy: 0.9063\n",
      "\n",
      "Epoch 00007: saving model to History0/model.epoch07.hdf5\n",
      "Epoch 8/150\n",
      "105/105 [==============================] - 52s 491ms/step - loss: 0.7524 - accuracy: 0.5747 - auc: 0.5788 - categorical_crossentropy: 0.7597 - val_loss: 0.9155 - val_accuracy: 0.3267 - val_auc: 0.2908 - val_categorical_crossentropy: 0.9155\n",
      "\n",
      "Epoch 00008: saving model to History0/model.epoch08.hdf5\n",
      "Epoch 9/150\n",
      "105/105 [==============================] - 53s 503ms/step - loss: 0.7551 - accuracy: 0.5554 - auc: 0.5632 - categorical_crossentropy: 0.7710 - val_loss: 0.8621 - val_accuracy: 0.3168 - val_auc: 0.3022 - val_categorical_crossentropy: 0.8621\n",
      "\n",
      "Epoch 00009: saving model to History0/model.epoch09.hdf5\n",
      "Epoch 10/150\n",
      "105/105 [==============================] - 55s 525ms/step - loss: 0.7280 - accuracy: 0.5105 - auc: 0.5446 - categorical_crossentropy: 0.7685 - val_loss: 0.8375 - val_accuracy: 0.3168 - val_auc: 0.3088 - val_categorical_crossentropy: 0.8375\n",
      "\n",
      "Epoch 00010: saving model to History0/model.epoch10.hdf5\n",
      "Epoch 11/150\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.7292 - accuracy: 0.5614 - auc: 0.5996 - categorical_crossentropy: 0.7180 - val_loss: 0.8457 - val_accuracy: 0.3267 - val_auc: 0.2956 - val_categorical_crossentropy: 0.8457\n",
      "\n",
      "Epoch 00011: saving model to History0/model.epoch11.hdf5\n",
      "Epoch 12/150\n",
      "105/105 [==============================] - 52s 500ms/step - loss: 0.8022 - accuracy: 0.5010 - auc: 0.5102 - categorical_crossentropy: 0.8055 - val_loss: 0.9791 - val_accuracy: 0.3168 - val_auc: 0.2884 - val_categorical_crossentropy: 0.9791\n",
      "\n",
      "Epoch 00012: saving model to History0/model.epoch12.hdf5\n",
      "Epoch 13/150\n",
      "105/105 [==============================] - 51s 488ms/step - loss: 0.7140 - accuracy: 0.5023 - auc: 0.5665 - categorical_crossentropy: 0.7700 - val_loss: 0.9731 - val_accuracy: 0.3168 - val_auc: 0.2911 - val_categorical_crossentropy: 0.9731\n",
      "\n",
      "Epoch 00013: saving model to History0/model.epoch13.hdf5\n",
      "Epoch 14/150\n",
      "105/105 [==============================] - 52s 493ms/step - loss: 0.7247 - accuracy: 0.4774 - auc: 0.5168 - categorical_crossentropy: 0.7798 - val_loss: 0.9450 - val_accuracy: 0.3168 - val_auc: 0.2972 - val_categorical_crossentropy: 0.9450\n",
      "\n",
      "Epoch 00014: saving model to History0/model.epoch14.hdf5\n",
      "Epoch 15/150\n",
      "105/105 [==============================] - 52s 498ms/step - loss: 0.6959 - accuracy: 0.6271 - auc: 0.6605 - categorical_crossentropy: 0.6728 - val_loss: 0.9412 - val_accuracy: 0.3168 - val_auc: 0.3001 - val_categorical_crossentropy: 0.9412\n",
      "\n",
      "Epoch 00015: saving model to History0/model.epoch15.hdf5\n",
      "Epoch 16/150\n",
      "105/105 [==============================] - 50s 479ms/step - loss: 0.7828 - accuracy: 0.4884 - auc: 0.4822 - categorical_crossentropy: 0.8286 - val_loss: 0.9166 - val_accuracy: 0.3168 - val_auc: 0.2970 - val_categorical_crossentropy: 0.9166\n",
      "\n",
      "Epoch 00016: saving model to History0/model.epoch16.hdf5\n",
      "Epoch 17/150\n",
      "105/105 [==============================] - 55s 519ms/step - loss: 0.7949 - accuracy: 0.4857 - auc: 0.4786 - categorical_crossentropy: 0.8235 - val_loss: 0.9207 - val_accuracy: 0.3168 - val_auc: 0.3124 - val_categorical_crossentropy: 0.9207\n",
      "\n",
      "Epoch 00017: saving model to History0/model.epoch17.hdf5\n",
      "Epoch 18/150\n",
      "105/105 [==============================] - 54s 516ms/step - loss: 0.7363 - accuracy: 0.5303 - auc: 0.5437 - categorical_crossentropy: 0.7546 - val_loss: 0.8692 - val_accuracy: 0.3168 - val_auc: 0.3116 - val_categorical_crossentropy: 0.8692\n",
      "\n",
      "Epoch 00018: saving model to History0/model.epoch18.hdf5\n",
      "Epoch 19/150\n",
      "105/105 [==============================] - 51s 486ms/step - loss: 0.7214 - accuracy: 0.5253 - auc: 0.5606 - categorical_crossentropy: 0.7481 - val_loss: 0.8989 - val_accuracy: 0.3168 - val_auc: 0.3171 - val_categorical_crossentropy: 0.8989\n",
      "\n",
      "Epoch 00019: saving model to History0/model.epoch19.hdf5\n",
      "Epoch 20/150\n",
      "105/105 [==============================] - 54s 512ms/step - loss: 0.6813 - accuracy: 0.5485 - auc: 0.6120 - categorical_crossentropy: 0.7134 - val_loss: 1.0017 - val_accuracy: 0.3366 - val_auc: 0.3070 - val_categorical_crossentropy: 1.0017\n",
      "\n",
      "Epoch 00020: saving model to History0/model.epoch20.hdf5\n",
      "Epoch 21/150\n",
      "105/105 [==============================] - 51s 483ms/step - loss: 0.7182 - accuracy: 0.5953 - auc: 0.6174 - categorical_crossentropy: 0.7452 - val_loss: 1.0372 - val_accuracy: 0.3168 - val_auc: 0.3106 - val_categorical_crossentropy: 1.0372\n",
      "\n",
      "Epoch 00021: saving model to History0/model.epoch21.hdf5\n",
      "Epoch 22/150\n",
      "105/105 [==============================] - 50s 481ms/step - loss: 0.7401 - accuracy: 0.5029 - auc: 0.5183 - categorical_crossentropy: 0.8058 - val_loss: 0.9068 - val_accuracy: 0.3168 - val_auc: 0.3025 - val_categorical_crossentropy: 0.9068\n",
      "\n",
      "Epoch 00022: saving model to History0/model.epoch22.hdf5\n",
      "Epoch 23/150\n",
      "105/105 [==============================] - 51s 485ms/step - loss: 0.7340 - accuracy: 0.5246 - auc: 0.5513 - categorical_crossentropy: 0.7476 - val_loss: 0.9191 - val_accuracy: 0.3168 - val_auc: 0.3120 - val_categorical_crossentropy: 0.9191\n",
      "\n",
      "Epoch 00023: saving model to History0/model.epoch23.hdf5\n",
      "Epoch 24/150\n",
      "105/105 [==============================] - 49s 468ms/step - loss: 0.7446 - accuracy: 0.5060 - auc: 0.5176 - categorical_crossentropy: 0.7936 - val_loss: 0.8690 - val_accuracy: 0.3366 - val_auc: 0.3200 - val_categorical_crossentropy: 0.8690\n",
      "\n",
      "Epoch 00024: saving model to History0/model.epoch24.hdf5\n",
      "Epoch 25/150\n",
      "105/105 [==============================] - 54s 515ms/step - loss: 0.7048 - accuracy: 0.5422 - auc: 0.5788 - categorical_crossentropy: 0.7300 - val_loss: 0.9322 - val_accuracy: 0.3267 - val_auc: 0.3235 - val_categorical_crossentropy: 0.9322\n",
      "\n",
      "Epoch 00025: saving model to History0/model.epoch25.hdf5\n",
      "Epoch 26/150\n",
      "105/105 [==============================] - 52s 496ms/step - loss: 0.7672 - accuracy: 0.4929 - auc: 0.4985 - categorical_crossentropy: 0.8165 - val_loss: 0.7871 - val_accuracy: 0.3267 - val_auc: 0.3276 - val_categorical_crossentropy: 0.7871\n",
      "\n",
      "Epoch 00026: saving model to History0/model.epoch26.hdf5\n",
      "Epoch 27/150\n",
      "105/105 [==============================] - 55s 519ms/step - loss: 0.7123 - accuracy: 0.5596 - auc: 0.5519 - categorical_crossentropy: 0.7340 - val_loss: 0.9227 - val_accuracy: 0.3366 - val_auc: 0.3174 - val_categorical_crossentropy: 0.9227\n",
      "\n",
      "Epoch 00027: saving model to History0/model.epoch27.hdf5\n",
      "Epoch 28/150\n",
      "105/105 [==============================] - 51s 488ms/step - loss: 0.7259 - accuracy: 0.5303 - auc: 0.5690 - categorical_crossentropy: 0.7261 - val_loss: 0.9904 - val_accuracy: 0.3168 - val_auc: 0.3229 - val_categorical_crossentropy: 0.9904\n",
      "\n",
      "Epoch 00028: saving model to History0/model.epoch28.hdf5\n",
      "Epoch 29/150\n",
      "105/105 [==============================] - 52s 494ms/step - loss: 0.7473 - accuracy: 0.5519 - auc: 0.5513 - categorical_crossentropy: 0.7622 - val_loss: 0.8514 - val_accuracy: 0.3465 - val_auc: 0.3272 - val_categorical_crossentropy: 0.8514\n",
      "\n",
      "Epoch 00029: saving model to History0/model.epoch29.hdf5\n",
      "Epoch 30/150\n",
      "105/105 [==============================] - 52s 499ms/step - loss: 0.7055 - accuracy: 0.5725 - auc: 0.6299 - categorical_crossentropy: 0.7043 - val_loss: 0.8881 - val_accuracy: 0.3366 - val_auc: 0.3244 - val_categorical_crossentropy: 0.8881\n",
      "\n",
      "Epoch 00030: saving model to History0/model.epoch30.hdf5\n",
      "Epoch 31/150\n",
      "105/105 [==============================] - 52s 498ms/step - loss: 0.7431 - accuracy: 0.5097 - auc: 0.5112 - categorical_crossentropy: 0.7861 - val_loss: 0.9618 - val_accuracy: 0.3168 - val_auc: 0.3231 - val_categorical_crossentropy: 0.9618\n",
      "\n",
      "Epoch 00031: saving model to History0/model.epoch31.hdf5\n",
      "Epoch 32/150\n",
      "105/105 [==============================] - 51s 488ms/step - loss: 0.6803 - accuracy: 0.6009 - auc: 0.6550 - categorical_crossentropy: 0.6928 - val_loss: 1.0704 - val_accuracy: 0.3168 - val_auc: 0.3085 - val_categorical_crossentropy: 1.0704\n",
      "\n",
      "Epoch 00032: saving model to History0/model.epoch32.hdf5\n",
      "Epoch 33/150\n",
      "105/105 [==============================] - 56s 533ms/step - loss: 0.7531 - accuracy: 0.4776 - auc: 0.4911 - categorical_crossentropy: 0.8178 - val_loss: 0.9610 - val_accuracy: 0.3267 - val_auc: 0.3210 - val_categorical_crossentropy: 0.9610\n",
      "\n",
      "Epoch 00033: saving model to History0/model.epoch33.hdf5\n",
      "Epoch 34/150\n",
      "105/105 [==============================] - 51s 486ms/step - loss: 0.7121 - accuracy: 0.5480 - auc: 0.5805 - categorical_crossentropy: 0.7473 - val_loss: 1.0557 - val_accuracy: 0.3168 - val_auc: 0.3164 - val_categorical_crossentropy: 1.0557\n",
      "\n",
      "Epoch 00034: saving model to History0/model.epoch34.hdf5\n",
      "Epoch 35/150\n",
      "105/105 [==============================] - 53s 505ms/step - loss: 0.7119 - accuracy: 0.5197 - auc: 0.5495 - categorical_crossentropy: 0.7561 - val_loss: 0.9517 - val_accuracy: 0.3267 - val_auc: 0.3210 - val_categorical_crossentropy: 0.9517\n",
      "\n",
      "Epoch 00035: saving model to History0/model.epoch35.hdf5\n",
      "Epoch 36/150\n",
      "105/105 [==============================] - 51s 483ms/step - loss: 0.7338 - accuracy: 0.5758 - auc: 0.5914 - categorical_crossentropy: 0.7274 - val_loss: 0.9775 - val_accuracy: 0.3366 - val_auc: 0.3197 - val_categorical_crossentropy: 0.9775\n",
      "\n",
      "Epoch 00036: saving model to History0/model.epoch36.hdf5\n",
      "Epoch 37/150\n",
      "105/105 [==============================] - 50s 472ms/step - loss: 0.6908 - accuracy: 0.5230 - auc: 0.5673 - categorical_crossentropy: 0.7460 - val_loss: 1.0366 - val_accuracy: 0.3267 - val_auc: 0.3156 - val_categorical_crossentropy: 1.0366\n",
      "\n",
      "Epoch 00037: saving model to History0/model.epoch37.hdf5\n",
      "Epoch 38/150\n",
      "105/105 [==============================] - 51s 482ms/step - loss: 0.7084 - accuracy: 0.5010 - auc: 0.5507 - categorical_crossentropy: 0.7574 - val_loss: 0.9338 - val_accuracy: 0.3267 - val_auc: 0.3150 - val_categorical_crossentropy: 0.9338\n",
      "\n",
      "Epoch 00038: saving model to History0/model.epoch38.hdf5\n",
      "Epoch 39/150\n",
      "105/105 [==============================] - 51s 488ms/step - loss: 0.6978 - accuracy: 0.5758 - auc: 0.5836 - categorical_crossentropy: 0.7267 - val_loss: 0.9627 - val_accuracy: 0.3465 - val_auc: 0.3124 - val_categorical_crossentropy: 0.9627\n",
      "\n",
      "Epoch 00039: saving model to History0/model.epoch39.hdf5\n",
      "Epoch 40/150\n",
      "105/105 [==============================] - 51s 484ms/step - loss: 0.6618 - accuracy: 0.6234 - auc: 0.6634 - categorical_crossentropy: 0.6849 - val_loss: 1.0216 - val_accuracy: 0.3267 - val_auc: 0.3000 - val_categorical_crossentropy: 1.0216\n",
      "\n",
      "Epoch 00040: saving model to History0/model.epoch40.hdf5\n",
      "Epoch 41/150\n",
      "105/105 [==============================] - 51s 485ms/step - loss: 0.6757 - accuracy: 0.6264 - auc: 0.6524 - categorical_crossentropy: 0.6953 - val_loss: 1.0872 - val_accuracy: 0.3267 - val_auc: 0.3070 - val_categorical_crossentropy: 1.0872\n",
      "\n",
      "Epoch 00041: saving model to History0/model.epoch41.hdf5\n",
      "Epoch 42/150\n",
      "105/105 [==============================] - 53s 502ms/step - loss: 0.6775 - accuracy: 0.5466 - auc: 0.5884 - categorical_crossentropy: 0.7295 - val_loss: 0.9439 - val_accuracy: 0.3366 - val_auc: 0.3102 - val_categorical_crossentropy: 0.9439\n",
      "\n",
      "Epoch 00042: saving model to History0/model.epoch42.hdf5\n",
      "Epoch 43/150\n",
      "105/105 [==============================] - 51s 485ms/step - loss: 0.6507 - accuracy: 0.6421 - auc: 0.6754 - categorical_crossentropy: 0.6549 - val_loss: 0.9549 - val_accuracy: 0.3465 - val_auc: 0.3266 - val_categorical_crossentropy: 0.9549\n",
      "\n",
      "Epoch 00043: saving model to History0/model.epoch43.hdf5\n",
      "Epoch 44/150\n",
      "105/105 [==============================] - 54s 517ms/step - loss: 0.6806 - accuracy: 0.5646 - auc: 0.6178 - categorical_crossentropy: 0.7000 - val_loss: 1.0309 - val_accuracy: 0.3366 - val_auc: 0.3235 - val_categorical_crossentropy: 1.0309\n",
      "\n",
      "Epoch 00044: saving model to History0/model.epoch44.hdf5\n",
      "Epoch 45/150\n",
      "105/105 [==============================] - 53s 503ms/step - loss: 0.6948 - accuracy: 0.5951 - auc: 0.6028 - categorical_crossentropy: 0.7262 - val_loss: 0.9484 - val_accuracy: 0.3465 - val_auc: 0.3187 - val_categorical_crossentropy: 0.9484\n",
      "\n",
      "Epoch 00045: saving model to History0/model.epoch45.hdf5\n",
      "Epoch 46/150\n",
      "105/105 [==============================] - 53s 505ms/step - loss: 0.6738 - accuracy: 0.5578 - auc: 0.6191 - categorical_crossentropy: 0.6910 - val_loss: 0.9665 - val_accuracy: 0.3465 - val_auc: 0.3215 - val_categorical_crossentropy: 0.9665\n",
      "\n",
      "Epoch 00046: saving model to History0/model.epoch46.hdf5\n",
      "Epoch 47/150\n",
      "105/105 [==============================] - 52s 498ms/step - loss: 0.6806 - accuracy: 0.5702 - auc: 0.5985 - categorical_crossentropy: 0.7123 - val_loss: 1.1370 - val_accuracy: 0.3168 - val_auc: 0.3024 - val_categorical_crossentropy: 1.1370\n",
      "\n",
      "Epoch 00047: saving model to History0/model.epoch47.hdf5\n",
      "Epoch 48/150\n",
      "105/105 [==============================] - 50s 477ms/step - loss: 0.6927 - accuracy: 0.5638 - auc: 0.6005 - categorical_crossentropy: 0.7312 - val_loss: 0.9047 - val_accuracy: 0.3465 - val_auc: 0.3200 - val_categorical_crossentropy: 0.9047\n",
      "\n",
      "Epoch 00048: saving model to History0/model.epoch48.hdf5\n",
      "Epoch 49/150\n",
      "105/105 [==============================] - 54s 519ms/step - loss: 0.6905 - accuracy: 0.5724 - auc: 0.6076 - categorical_crossentropy: 0.7015 - val_loss: 0.9655 - val_accuracy: 0.3267 - val_auc: 0.3163 - val_categorical_crossentropy: 0.9655\n",
      "\n",
      "Epoch 00049: saving model to History0/model.epoch49.hdf5\n",
      "Epoch 50/150\n",
      "105/105 [==============================] - 54s 512ms/step - loss: 0.6826 - accuracy: 0.5285 - auc: 0.5918 - categorical_crossentropy: 0.7188 - val_loss: 0.9482 - val_accuracy: 0.3267 - val_auc: 0.3207 - val_categorical_crossentropy: 0.9482\n",
      "\n",
      "Epoch 00050: saving model to History0/model.epoch50.hdf5\n",
      "Epoch 51/150\n",
      "105/105 [==============================] - 52s 493ms/step - loss: 0.6932 - accuracy: 0.5620 - auc: 0.5921 - categorical_crossentropy: 0.7202 - val_loss: 1.0671 - val_accuracy: 0.3168 - val_auc: 0.3228 - val_categorical_crossentropy: 1.0671\n",
      "\n",
      "Epoch 00051: saving model to History0/model.epoch51.hdf5\n",
      "Epoch 52/150\n",
      "105/105 [==============================] - 52s 495ms/step - loss: 0.6969 - accuracy: 0.5700 - auc: 0.6052 - categorical_crossentropy: 0.7165 - val_loss: 0.9344 - val_accuracy: 0.3267 - val_auc: 0.3243 - val_categorical_crossentropy: 0.9344\n",
      "\n",
      "Epoch 00052: saving model to History0/model.epoch52.hdf5\n",
      "Epoch 53/150\n",
      "105/105 [==============================] - 50s 475ms/step - loss: 0.6447 - accuracy: 0.5615 - auc: 0.6240 - categorical_crossentropy: 0.6857 - val_loss: 1.0008 - val_accuracy: 0.3366 - val_auc: 0.3319 - val_categorical_crossentropy: 1.0008\n",
      "\n",
      "Epoch 00053: saving model to History0/model.epoch53.hdf5\n",
      "Epoch 54/150\n",
      "105/105 [==============================] - 52s 499ms/step - loss: 0.6542 - accuracy: 0.5902 - auc: 0.6392 - categorical_crossentropy: 0.6874 - val_loss: 0.8858 - val_accuracy: 0.3762 - val_auc: 0.3631 - val_categorical_crossentropy: 0.8858\n",
      "\n",
      "Epoch 00054: saving model to History0/model.epoch54.hdf5\n",
      "Epoch 55/150\n",
      "105/105 [==============================] - 51s 480ms/step - loss: 0.6481 - accuracy: 0.6270 - auc: 0.6722 - categorical_crossentropy: 0.6687 - val_loss: 0.9651 - val_accuracy: 0.3366 - val_auc: 0.3313 - val_categorical_crossentropy: 0.9651\n",
      "\n",
      "Epoch 00055: saving model to History0/model.epoch55.hdf5\n",
      "Epoch 56/150\n",
      "105/105 [==============================] - 56s 530ms/step - loss: 0.7237 - accuracy: 0.4985 - auc: 0.5512 - categorical_crossentropy: 0.7686 - val_loss: 1.1288 - val_accuracy: 0.3267 - val_auc: 0.3306 - val_categorical_crossentropy: 1.1288\n",
      "\n",
      "Epoch 00056: saving model to History0/model.epoch56.hdf5\n",
      "Epoch 57/150\n",
      "105/105 [==============================] - 53s 504ms/step - loss: 0.6981 - accuracy: 0.5413 - auc: 0.5775 - categorical_crossentropy: 0.7619 - val_loss: 0.9452 - val_accuracy: 0.3267 - val_auc: 0.3438 - val_categorical_crossentropy: 0.9452\n",
      "\n",
      "Epoch 00057: saving model to History0/model.epoch57.hdf5\n",
      "Epoch 58/150\n",
      "105/105 [==============================] - 51s 491ms/step - loss: 0.6539 - accuracy: 0.5954 - auc: 0.6377 - categorical_crossentropy: 0.7117 - val_loss: 0.8355 - val_accuracy: 0.3861 - val_auc: 0.3526 - val_categorical_crossentropy: 0.8355\n",
      "\n",
      "Epoch 00058: saving model to History0/model.epoch58.hdf5\n",
      "Epoch 59/150\n",
      "105/105 [==============================] - 54s 508ms/step - loss: 0.7366 - accuracy: 0.5896 - auc: 0.6048 - categorical_crossentropy: 0.7187 - val_loss: 1.0275 - val_accuracy: 0.3267 - val_auc: 0.3209 - val_categorical_crossentropy: 1.0275\n",
      "\n",
      "Epoch 00059: saving model to History0/model.epoch59.hdf5\n",
      "Epoch 60/150\n",
      "105/105 [==============================] - 52s 493ms/step - loss: 0.6408 - accuracy: 0.6116 - auc: 0.6606 - categorical_crossentropy: 0.6671 - val_loss: 1.0574 - val_accuracy: 0.3366 - val_auc: 0.3259 - val_categorical_crossentropy: 1.0574\n",
      "\n",
      "Epoch 00060: saving model to History0/model.epoch60.hdf5\n",
      "Epoch 61/150\n",
      "105/105 [==============================] - 54s 516ms/step - loss: 0.6187 - accuracy: 0.5841 - auc: 0.6830 - categorical_crossentropy: 0.6550 - val_loss: 0.8746 - val_accuracy: 0.3465 - val_auc: 0.3547 - val_categorical_crossentropy: 0.8746\n",
      "\n",
      "Epoch 00061: saving model to History0/model.epoch61.hdf5\n",
      "Epoch 62/150\n",
      "105/105 [==============================] - 55s 521ms/step - loss: 0.6493 - accuracy: 0.5828 - auc: 0.6396 - categorical_crossentropy: 0.6955 - val_loss: 0.8789 - val_accuracy: 0.3762 - val_auc: 0.3708 - val_categorical_crossentropy: 0.8789\n",
      "\n",
      "Epoch 00062: saving model to History0/model.epoch62.hdf5\n",
      "Epoch 63/150\n",
      "105/105 [==============================] - 52s 494ms/step - loss: 0.6976 - accuracy: 0.5893 - auc: 0.6247 - categorical_crossentropy: 0.7124 - val_loss: 0.9967 - val_accuracy: 0.3366 - val_auc: 0.3465 - val_categorical_crossentropy: 0.9967\n",
      "\n",
      "Epoch 00063: saving model to History0/model.epoch63.hdf5\n",
      "Epoch 64/150\n",
      "105/105 [==============================] - 54s 513ms/step - loss: 0.6502 - accuracy: 0.5549 - auc: 0.6284 - categorical_crossentropy: 0.6906 - val_loss: 0.8840 - val_accuracy: 0.3564 - val_auc: 0.3616 - val_categorical_crossentropy: 0.8840\n",
      "\n",
      "Epoch 00064: saving model to History0/model.epoch64.hdf5\n",
      "Epoch 65/150\n",
      "105/105 [==============================] - 51s 487ms/step - loss: 0.6747 - accuracy: 0.5942 - auc: 0.6430 - categorical_crossentropy: 0.6830 - val_loss: 1.0261 - val_accuracy: 0.3564 - val_auc: 0.3333 - val_categorical_crossentropy: 1.0261\n",
      "\n",
      "Epoch 00065: saving model to History0/model.epoch65.hdf5\n",
      "Epoch 66/150\n",
      "105/105 [==============================] - 53s 503ms/step - loss: 0.6890 - accuracy: 0.5453 - auc: 0.6129 - categorical_crossentropy: 0.7187 - val_loss: 1.0227 - val_accuracy: 0.3168 - val_auc: 0.3320 - val_categorical_crossentropy: 1.0227\n",
      "\n",
      "Epoch 00066: saving model to History0/model.epoch66.hdf5\n",
      "Epoch 67/150\n",
      "105/105 [==============================] - 53s 502ms/step - loss: 0.6817 - accuracy: 0.5539 - auc: 0.6042 - categorical_crossentropy: 0.7331 - val_loss: 1.0905 - val_accuracy: 0.3168 - val_auc: 0.3386 - val_categorical_crossentropy: 1.0905\n",
      "\n",
      "Epoch 00067: saving model to History0/model.epoch67.hdf5\n",
      "Epoch 68/150\n",
      "105/105 [==============================] - 51s 487ms/step - loss: 0.6500 - accuracy: 0.5829 - auc: 0.6681 - categorical_crossentropy: 0.6789 - val_loss: 0.8828 - val_accuracy: 0.3762 - val_auc: 0.3591 - val_categorical_crossentropy: 0.8828\n",
      "\n",
      "Epoch 00068: saving model to History0/model.epoch68.hdf5\n",
      "Epoch 69/150\n",
      "105/105 [==============================] - 54s 516ms/step - loss: 0.6514 - accuracy: 0.6106 - auc: 0.6512 - categorical_crossentropy: 0.6758 - val_loss: 1.0663 - val_accuracy: 0.3366 - val_auc: 0.3403 - val_categorical_crossentropy: 1.0663\n",
      "\n",
      "Epoch 00069: saving model to History0/model.epoch69.hdf5\n",
      "Epoch 70/150\n",
      "105/105 [==============================] - 53s 508ms/step - loss: 0.6679 - accuracy: 0.6002 - auc: 0.6451 - categorical_crossentropy: 0.7043 - val_loss: 0.9374 - val_accuracy: 0.3168 - val_auc: 0.3470 - val_categorical_crossentropy: 0.9374\n",
      "\n",
      "Epoch 00070: saving model to History0/model.epoch70.hdf5\n",
      "Epoch 71/150\n",
      "105/105 [==============================] - 50s 478ms/step - loss: 0.6692 - accuracy: 0.5634 - auc: 0.6183 - categorical_crossentropy: 0.6991 - val_loss: 1.0693 - val_accuracy: 0.3168 - val_auc: 0.3393 - val_categorical_crossentropy: 1.0693\n",
      "\n",
      "Epoch 00071: saving model to History0/model.epoch71.hdf5\n",
      "Epoch 72/150\n",
      "105/105 [==============================] - 53s 502ms/step - loss: 0.6114 - accuracy: 0.6113 - auc: 0.6927 - categorical_crossentropy: 0.6479 - val_loss: 0.9989 - val_accuracy: 0.3366 - val_auc: 0.3371 - val_categorical_crossentropy: 0.9989\n",
      "\n",
      "Epoch 00072: saving model to History0/model.epoch72.hdf5\n",
      "Epoch 73/150\n",
      "105/105 [==============================] - 53s 511ms/step - loss: 0.5969 - accuracy: 0.6541 - auc: 0.7164 - categorical_crossentropy: 0.6375 - val_loss: 1.0648 - val_accuracy: 0.3564 - val_auc: 0.3408 - val_categorical_crossentropy: 1.0648\n",
      "\n",
      "Epoch 00073: saving model to History0/model.epoch73.hdf5\n",
      "Epoch 74/150\n",
      "102/105 [============================>.] - ETA: 1s - loss: 0.6695 - accuracy: 0.6144 - auc: 0.6614 - categorical_crossentropy: 0.6955"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 5\n",
    "\n",
    "## get stroke and tia indeces\n",
    "stroke_idx = np.where(Y_pat == 1)\n",
    "tia_idx = np.where(Y_pat == 0)\n",
    "\n",
    "## shuffle indeces\n",
    "np.random.seed(2021)\n",
    "np.random.shuffle(stroke_idx[0])\n",
    "np.random.shuffle(tia_idx[0])\n",
    "\n",
    "## split indeces into 5 parts\n",
    "splits_stroke = np.array_split(stroke_idx[0],N_FOLDS)\n",
    "splits_tia = np.array_split(tia_idx[0], [31,62,93,125])\n",
    "\n",
    "## define chosen splits for each fold\n",
    "test_folds = [0, 1, 2, 3, 4]\n",
    "valid_folds = [1, 2, 3, 4, 0]\n",
    "train_folds = [[0, 1], [1, 2], [2, 3], [3, 4], [0, 4]] ## remove these splits for training data\n",
    "\n",
    "for fold in range(N_FOLDS):\n",
    "    \n",
    "    ## define train, test and validation splits\n",
    "    test_idx = np.concatenate((splits_stroke[test_folds[fold]], splits_tia[test_folds[fold]]), axis = None)\n",
    "    valid_idx = np.concatenate((splits_stroke[valid_folds[fold]], splits_tia[valid_folds[fold]]), axis = None)\n",
    "\n",
    "    train_stroke = np.delete(splits_stroke, train_folds[fold], 0)\n",
    "    train_stroke = [item for sublist in train_stroke for item in sublist]\n",
    "    \n",
    "    train_tia = np.delete(splits_tia, train_folds[fold], 0)\n",
    "    train_tia = [item for sublist in train_tia for item in sublist]\n",
    "    \n",
    "    train_idx = np.concatenate((train_stroke, train_tia), axis = None)\n",
    "    \n",
    "    X_train = X[train_idx]\n",
    "    X_test = X[test_idx]\n",
    "    X_valid = X[valid_idx]\n",
    "    \n",
    "    Y_train = Y_pat[train_idx]\n",
    "    Y_test = Y_pat[test_idx]\n",
    "    Y_valid = Y_pat[valid_idx]\n",
    "    \n",
    "    pat_train = pat[train_idx]\n",
    "    pat_test = pat[test_idx]\n",
    "    pat_valid = pat[valid_idx]\n",
    "    \n",
    "    #get resampled dataset\n",
    "    train_dataset, validation_dataset, class_weight, batch_size, resampled_steps_per_epoch = get_dataset(X_train, Y_train, X_valid, Y_valid)\n",
    "    \n",
    "    #get model\n",
    "    model = get_model(X_train[0].shape)\n",
    "    print(model.summary())\n",
    "    \n",
    "    ### define metrics\n",
    "    metrics = [\n",
    "    keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    keras.metrics.AUC(name='auc'),\n",
    "    keras.metrics.CategoricalCrossentropy(name=\"categorical_crossentropy\")]\n",
    "\n",
    "    ### prepare files for logging\n",
    "    results_filepath = 'results'+str(fold)+'.csv'\n",
    "    if os.path.exists(results_filepath):\n",
    "        os.remove(results_filepath)\n",
    "    \n",
    "    history_filepath = 'History'+str(fold)\n",
    "    if os.path.isdir(history_filepath):\n",
    "        shutil.rmtree(history_filepath )\n",
    "    os.makedirs(history_filepath )\n",
    "\n",
    "    epochs_filepath = history_filepath+'/model.epoch{epoch:02d}.hdf5'\n",
    "\n",
    "    ### define callback_list\n",
    "    callback_list = [\n",
    "    keras.callbacks.ModelCheckpoint(filepath=epochs_filepath, save_freq='epoch', verbose=1), \n",
    "    keras.callbacks.CSVLogger(results_filepath)]\n",
    "\n",
    "    ### compile model\n",
    "    model.compile(loss = \"categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate =  0.00001),\n",
    "    metrics = metrics)\n",
    "    \n",
    "    ###train model\n",
    "    epochs = 150\n",
    "    hist = model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=validation_dataset,\n",
    "        epochs=epochs,\n",
    "        verbose=1, callbacks=callback_list, \n",
    "        steps_per_epoch = resampled_steps_per_epoch,\n",
    "        class_weight = class_weight)\n",
    "    \n",
    "    ###use epoch with minimal validation loss from the tenth epoch\n",
    "    dat = pd.read_csv(results_filepath, index_col='epoch')\n",
    "    best_model = np.where(dat.val_loss == np.min(dat.val_loss[10:]))[0][0] \n",
    "    best_model = best_model + 1\n",
    "    model.load_weights(history_filepath+'/model.epoch'+str(best_model)+'.hdf5')\n",
    "    \n",
    "    y_prob = model.predict(X_test, batch_size=batch_size)\n",
    "    y_pred = (y_prob[:,1] > 0.5).astype(np.int)\n",
    "    \n",
    "    #calculate categorical crossentropy\n",
    "    Y_test_cat = to_categorical(Y_test)\n",
    "    m = tf.keras.metrics.CategoricalCrossentropy()\n",
    "    m.update_state(Y_test_cat, y_prob)\n",
    "    catcrossentropy = m.result().numpy()\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df.loc[:,\"pat_id\"] = list(pat_test)\n",
    "    df.loc[:,\"y_test\"] = Y_test\n",
    "    df.loc[:,\"y_pred\"] = y_pred\n",
    "    df.loc[:,\"y_prob\"] = y_prob[:,1]\n",
    "    df.loc[:,\"cat_cross\"] = list(np.repeat(catcrossentropy, len(y_pred)))\n",
    "    df.loc[:,\"fold\"] = list(np.repeat(fold, len(y_pred)))\n",
    "    \n",
    "    df.to_csv(\"predictions\"+str(fold)+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surrounded-collaboration",
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge predictions from 5folds to one file\n",
    "pred0 = pd.read_csv('predictions0.csv', index_col = False)\n",
    "pred1 = pd.read_csv('predictions1.csv', index_col = False)\n",
    "pred2 = pd.read_csv('predictions2.csv', index_col = False)\n",
    "pred3 = pd.read_csv('predictions3.csv', index_col = False)\n",
    "pred4 = pd.read_csv('predictions4.csv', index_col = False)\n",
    "\n",
    "merged = pd.concat([pred0, pred1, pred2, pred3, pred4], axis=0)\n",
    "merged = merged.reset_index()\n",
    "merged.to_csv('pred5fold.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

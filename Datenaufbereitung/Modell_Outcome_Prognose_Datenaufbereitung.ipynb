{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Functions.image_preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_3D_H5 = 'Images/tof_data_128_112_40_outcome.hdf5'\n",
    "\n",
    "def decode_data(string):\n",
    "    decoded_string = [n.decode(\"UTF-8\", \"ignore\") for n in string]\n",
    "    return(decoded_string)\n",
    "\n",
    "with h5py.File(PATH_3D_H5, 'r') as h5:\n",
    "    print('H5-file: ', list(h5.keys()))\n",
    "    \n",
    "    # Image matrices\n",
    "    X = h5[\"X\"][:]\n",
    "    # Patient ID's\n",
    "    pat = h5[\"pat\"][:]\n",
    "    # Path to images\n",
    "    path = decode_data(h5[\"path\"][:])\n",
    "    # Patient labels (1=bad outcome, 0=good outcome)\n",
    "    Y_outcome = h5[\"stroke\"][:]\n",
    "    \n",
    "print(len(X), len(Y_outcome), len(pat), len(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expand dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.expand_dims(X, axis = 4)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values between 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = np.empty_like(X)\n",
    "\n",
    "for i in range(X.shape[0]):\n",
    "    X_norm[i] = normalize(X[i])  \n",
    "    \n",
    "print(X_norm.shape, X_norm.min(), X_norm.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_normz = np.array([z_normalize(img) for img in X_norm])\n",
    "print(X_normz.shape, X_normz.min(), X_normz.max(), X_normz.mean(), X_normz.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 40)) # total figure size (including all subplots)\n",
    "fig_all = []\n",
    "img = np.squeeze(X_normz[0], axis = 3)\n",
    "for i in range(1, 39):\n",
    "    image = img[:,:,i]\n",
    "    fig_all.append(fig.add_subplot(8, 5, i))\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save in hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the preprocessed data\n",
    "with h5py.File('Images/preprocessed_data_128_112_40_outcome.hdf5', \"w\") as h5:\n",
    "    h5.create_dataset(\"X\", data = X_normz)\n",
    "    h5.create_dataset(\"Y_outcome\", data = Y_outcome)\n",
    "    h5.create_dataset(\"pat\", data = pat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
